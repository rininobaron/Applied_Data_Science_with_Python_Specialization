{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cacf7f4360d6d53c622742f64048f72c",
     "grade": false,
     "grade_id": "cell-8a754c8ce8a16eeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices. **This Series should be sorted by a tie-break sort in the format of (\"extracted date\", \"original row number\").**\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b47ce38a503bfb1f113580f394d8667",
     "grade": false,
     "grade_id": "cell-28048f36edc32946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "5                    .Per 7/06/79 Movement D/O note:\\n\n",
       "6    4, 5/18/78 Patient's thoughts about current su...\n",
       "7    10/24/89 CPT Code: 90801 - Psychiatric Diagnos...\n",
       "8                         3/7/86 SOS-10 Total Score:\\n\n",
       "9             (4/10/71)Score-1Audit C Score Current:\\n\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "doc = []\n",
    "with open('assets/dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e58e227860ae4b02d6bdddd81506787",
     "grade": false,
     "grade_id": "cell-d6f35a51303ed6ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "      ... \n",
       "495    427\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_sorter():\n",
    "    \n",
    "    order = None\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    mydf=df.copy()\n",
    "    \n",
    "    # Get dates\n",
    "    \n",
    "    suma_tolal = 0\n",
    "    # print(df.shape)\n",
    "    df1 = mydf.str.extractall(r'(?P<date>[^\\d]?(?P<month>\\d?\\d)/(?P<day>\\d?\\d)/(?P<year>[\\d]{4}|[\\d]{2})[^\\d])')\n",
    "    # display(df1)\n",
    "    # print(df1.shape[0])\n",
    "    # print(\"month\", df1[\"month\"].unique())\n",
    "    # print(\"day\", df1[\"day\"].unique())\n",
    "    # print(\"year\", df1[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df1.index, df1[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    # print(df1[\"date\"].tolist())\n",
    "    index_to_drop = []\n",
    "    index_to_drop.append([index[0] for index in df1.index])\n",
    "    mydf.drop(index_to_drop[0], inplace=True)\n",
    "    suma_tolal += df1.shape[0]\n",
    "    df2 = mydf.str.extractall(r'(?P<date>(?P<month>[A-Z][a-z]{2,})[-| |.][ ]?(?P<day>\\d?\\d)[-|,| ][ ]?(?P<year>[\\d]{4}))')\n",
    "    # print(df2.shape[0])\n",
    "    # print(\"month\", df2[\"month\"].unique())\n",
    "    # print(\"day\", df2[\"day\"].unique())\n",
    "    # print(\"year\", df2[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df2.index, df2[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    # Drop rows\n",
    "    df2.drop(df2[df2['month'] == 'Age'].index, inplace=True)\n",
    "    # print(df2.shape[0])\n",
    "    # print(df2[\"month\"].unique())\n",
    "    index_to_drop.append([index[0] for index in df2.index])\n",
    "    mydf.drop(index_to_drop[1], inplace=True)\n",
    "    suma_tolal += df2.shape[0]\n",
    "    df3 = mydf.str.extractall(r'(?P<date>(?P<day>\\d?\\d) (?P<month>[A-Z][a-z]{2,})[.|,]? (?P<year>[\\d]{4}))')\n",
    "    # display(df3)\n",
    "    # print(df3.shape[0])\n",
    "    # print(\"month\", df3[\"month\"].unique())\n",
    "    # print(\"day\", df3[\"day\"].unique())\n",
    "    # print(\"year\", df3[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df3.index, df3[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    # Drop \n",
    "    index_to_drop.append([index[0] for index in df3.index])\n",
    "    mydf.drop(index_to_drop[2], inplace=True)\n",
    "    suma_tolal += df3.shape[0]\n",
    "    # There is no examples for df4\n",
    "    # df4 = mydf.str.extractall(r'(?P<date>(?P<month>[A-Z][a-z]{2}) (?P<day>\\d?\\d[a-z]{2}), (?P<year>[\\d]{4}))')\n",
    "    # df4 = mydf.str.extractall(r'(?P<date>(?P<month>[A-Z][a-z]{2}) (?P<day>\\d?\\d)..)')\n",
    "    # display(df4)\n",
    "    # print(df4.shape[0])\n",
    "    # print(df4[\"day\"].unique())\n",
    "    index_to_drop.append([]) # Because there is no df4\n",
    "    df5 = mydf.str.extractall(r'(?P<date>[^\\d]?[ ]?(?P<month>[A-Z][a-z]{2,})[,]? (?P<year>[\\d]{4}))')\n",
    "    # display(df5)\n",
    "    # print(df5.shape[0])\n",
    "    # print(\"month\", df5[\"month\"].unique())\n",
    "    # # print(\"day\", df5[\"day\"].unique())\n",
    "    # print(\"year\", df5[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df5.index, df5[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    df5.drop(df5[df5['month'] == 'Since'].index, inplace=True)\n",
    "    # print(df5[\"month\"].unique())\n",
    "    # print(df5[\"date\"].tolist())\n",
    "    index_to_drop.append([index[0] for index in df5.index])\n",
    "    mydf.drop(index_to_drop[4], inplace=True)\n",
    "    suma_tolal += df5.shape[0]\n",
    "    df6 = mydf.str.extractall(r'(?P<date>(?P<month>\\d?\\d)/(?P<year>[\\d]{4}))')\n",
    "    # display(df6)\n",
    "    # print(df6.shape[0])\n",
    "    # print(\"month\", df6[\"month\"].unique())\n",
    "    # # print(\"day\", df6[\"day\"].unique())\n",
    "    # print(\"year\", df6[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df6.index, df6[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    index_to_drop.append([index[0] for index in df6.index])\n",
    "    mydf.drop(index_to_drop[5], inplace=True)\n",
    "    suma_tolal += df6.shape[0]\n",
    "    df7 = mydf.str.extractall(r'(?P<date>[^\\d]?(?P<year>[1|2][9|0][\\d]{2})[^\\d]?)')\n",
    "    # display(df7)\n",
    "    # print(df7.shape[0])\n",
    "    # # print(\"month\", df7[\"month\"].unique())\n",
    "    # # print(\"day\", df7[\"day\"].unique())\n",
    "    # print(\"year\", df7[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df7.index, df7[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    index_to_drop.append([index[0] for index in df7.index])\n",
    "    mydf.drop(index_to_drop[6], inplace=True)\n",
    "    suma_tolal += df7.shape[0]\n",
    "    df8 = mydf.str.extractall(r'(?P<date>[^\\d]?(?P<month>\\d?\\d)-(?P<day>\\d?\\d)-(?P<year>[\\d]{2})[^\\d])')\n",
    "    # display(df8)\n",
    "    # print(df8.shape[0])\n",
    "    # print(\"month\", df8[\"month\"].unique())\n",
    "    # print(\"day\", df8[\"day\"].unique())\n",
    "    # print(\"year\", df8[\"year\"].unique())\n",
    "    # for i, (index, value) in enumerate(zip(df8.index, df8[\"date\"].unique())):\n",
    "    #     print(i,value)\n",
    "    #     print(mydf.loc[index[0]])\n",
    "    index_to_drop.append([index[0] for index in df8.index])\n",
    "    mydf.drop(index_to_drop[7], inplace=True)\n",
    "    suma_tolal += df8.shape[0]\n",
    "    # print(\"suma total:\", suma_tolal)\n",
    "    # print(\"Faltan:\", 500-suma_tolal)\n",
    "    # print(mydf.shape[0])\n",
    "    # print(500-suma_tolal==mydf.shape[0])\n",
    "    # for row in mydf:\n",
    "    #     print(row)\n",
    "    #     print()\n",
    "    \n",
    "    # Create the dataframe with the series\n",
    "    \n",
    "    series = {key:[] for key in [\"month\", \"day\", \"year\"]}\n",
    "    \n",
    "    # print(index_to_drop[7])\n",
    "    # print()\n",
    "    # print(df8.index)\n",
    "    \n",
    "    # return None\n",
    "    \n",
    "    for i,df_ in enumerate([df1, df2, df3, None, df5, df6, df7, df8]):\n",
    "        if i == 3:\n",
    "            continue\n",
    "        temp = {}\n",
    "        # print(df_.index)\n",
    "        indexes = [index[0] for index in df_.index]\n",
    "        # print(indexes)\n",
    "        for column in [\"month\", \"day\", \"year\"]:\n",
    "            try:\n",
    "                temp[column] = df_[column]\n",
    "                temp[column].index = indexes\n",
    "            except:\n",
    "                temp[column] = pd.Series(['01']*df_.shape[0])\n",
    "                temp[column].index = indexes\n",
    "                temp[column].name = column\n",
    "            series[column].append(temp[column])\n",
    "        #     print(column)\n",
    "        #     print(temp[column])\n",
    "        #     print()\n",
    "        # print()\n",
    "    for key in series.keys():\n",
    "        # print(len(series[key]))\n",
    "        temp = pd.concat(series[key])\n",
    "        # print(len(temp))\n",
    "        # print(temp)\n",
    "        series[key] = temp\n",
    "    df_final=pd.DataFrame.from_dict(series)\n",
    "    # display(df_final)\n",
    "    # return df_final.index.unique()\n",
    "    \n",
    "    # Replace values with numeric values in column \"month\"\n",
    "    \n",
    "    months = [r\"January\", r\"February\", r\"March\", r\"April\", r\"May\", r\"June\", r\"July\", r\"August\", r\"September\", r\"October\", r\"November\", r\"December\"]\n",
    "    \n",
    "    # print(df_final[\"month\"].unique())\n",
    "    \n",
    "    temp = df_final[\"month\"].tolist()\n",
    "    \n",
    "    for i, item in enumerate(temp):\n",
    "        if len(item) == 1:\n",
    "            temp[i] = \"0\"+item\n",
    "            continue\n",
    "        for j, month in enumerate(months):\n",
    "            if month[0:3]==item[0:3]:\n",
    "                temp[i] = str(j+1)\n",
    "                if len(temp[i]) == 1:\n",
    "                    temp[i] = \"0\"+temp[i]\n",
    "                break\n",
    "    \n",
    "    df_final[\"month\"] = temp\n",
    "    \n",
    "    # for i, month in enumerate(months):\n",
    "    #     i = i+1\n",
    "    #     i = str(i)\n",
    "    #     if len(i) == 1:\n",
    "    #         i = \"0\"+i\n",
    "    #     df_final[\"month\"] = df_final[\"month\"].replace(month[0:3]+\"|\"+month, i, regex=True)\n",
    "    \n",
    "    # print(df_final[\"month\"].unique())\n",
    "    \n",
    "    # return False\n",
    "    \n",
    "    # Replace valus of column \"day\"\n",
    "    \n",
    "    # print(df_final[\"day\"].unique())\n",
    "    \n",
    "    # df_final[\"day\"] = df_final[\"day\"].astype(int)\n",
    "    \n",
    "    temp = df_final[\"day\"].tolist()\n",
    "    \n",
    "    for i, item in enumerate(temp):\n",
    "        if len(item) == 1:\n",
    "            temp[i] = \"0\"+item\n",
    "    \n",
    "    df_final[\"day\"] = temp\n",
    "    \n",
    "    # print(df_final[\"day\"].unique())\n",
    "    \n",
    "    # return False\n",
    "    \n",
    "    # Data wrangling in column \"year\"\n",
    "    \n",
    "    # print(df_final[\"year\"].unique())\n",
    "    \n",
    "    # temp=[]\n",
    "    # for value in df_final[\"year\"]:\n",
    "    #     if len(value) == 2:\n",
    "    #         temp.append(int(\"19\"+value))\n",
    "    #     else:\n",
    "    #         temp.append(int(value))\n",
    "    \n",
    "    temp = df_final[\"year\"].tolist()\n",
    "    \n",
    "    for i, item in enumerate(temp):\n",
    "        if len(item) == 2:\n",
    "            temp[i] = \"19\"+item\n",
    "            \n",
    "    df_final[\"year\"] = temp\n",
    "    \n",
    "    # print(df_final[\"year\"].unique())\n",
    "    \n",
    "    # return False\n",
    "    \n",
    "    # display(df_final)\n",
    "    \n",
    "    # Create new column \"date\"\n",
    "    \n",
    "    # display(pd.to_datetime(df_final))\n",
    "    dates = pd.to_datetime(df_final)\n",
    "    \n",
    "    # dates = df_final.apply(lambda x: x[0]+\"/\"+x[1]+\"/\"+x[2], axis=1)\n",
    "    \n",
    "    # Cast to datetime\n",
    "    \n",
    "    # dates = pd.to_datetime(dates)\n",
    "    \n",
    "    # display(df_final.sort_values(\"date\"))\n",
    "    \n",
    "    positions = dates.sort_values(kind = \"stable\").index.tolist()\n",
    "    \n",
    "    order = pd.Series(positions)\n",
    "    \n",
    "    # return display(order)\n",
    "    \n",
    "    #return display(df8[\"day\"])\n",
    "    #raise NotImplementedError()\n",
    "    return order # Your answer here\n",
    "#date_sorter()[\"year\"].unique()\n",
    "date_sorter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed df modification check\n",
      "Passed repeatability check\n",
      "Passed index check\n",
      "Passed secondary sort sample check\n",
      "Values checksums:\n",
      "     correct  learner  agree\n",
      "0       6695     6695   True\n",
      "10     14428    14428   True\n",
      "20     16742    16742   True\n",
      "30      9275     9275   True\n",
      "40     12290    12290   True\n",
      "50     14654    14654   True\n",
      "60      9421     9421   True\n",
      "70     10185    10185   True\n",
      "80     11464    11464   True\n",
      "90     16491    16491   True\n",
      "100    11797    11797   True\n",
      "110    14036    13941  False\n",
      "120    15459    15459   True\n",
      "130     9412     9412   True\n",
      "140    13069    13069   True\n",
      "150    10400    10400   True\n",
      "160    10498    10498   True\n",
      "170    14322    14322   True\n",
      "180    13274    13274   True\n",
      "190    11001    11001   True\n",
      "200    11383    11383   True\n",
      "210    11910    11910   True\n",
      "220    10977    10977   True\n",
      "230     9692     9692   True\n",
      "240    10199    10199   True\n",
      "250    10187    10187   True\n",
      "260    15456    15456   True\n",
      "270    13491    13491   True\n",
      "280     9186     9186   True\n",
      "290    13646    13646   True\n",
      "300    11142    11142   True\n",
      "310    13724    13724   True\n",
      "320    10994    10994   True\n",
      "330    12905    12905   True\n",
      "340    15968    15968   True\n",
      "350    16648    16648   True\n",
      "360    13966    13918  False\n",
      "370    14607    14607   True\n",
      "380    16932    16932   True\n",
      "390    14622    14622   True\n",
      "400    17942    17942   True\n",
      "410    18220    18220   True\n",
      "420    17818    17818   True\n",
      "430    18305    18305   True\n",
      "440    19633    19633   True\n",
      "450    12522    12522   True\n",
      "460    13978    13978   True\n",
      "470    18445    18445   True\n",
      "480    20156    20156   True\n",
      "490    14797    14797   True\n",
      "Failed values check\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "s_test = date_sorter()\n",
    "\n",
    "def run_df_modified_check():\n",
    "    \"\"\"\n",
    "    Check if df appears to be modified.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert type(df) == pd.Series\n",
    "        assert (df.index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "        assert (df.apply(type) == str).all()\n",
    "        assert df.str.len().min() >= 6\n",
    "        assert df.str[5].apply(ord).sum() == 38354\n",
    "        print(\"Passed df modification check\")\n",
    "    except:\n",
    "        print(\"Failed df modification check\")\n",
    "\n",
    "run_df_modified_check()\n",
    "\n",
    "# check if running the code twice produces the same result\n",
    "try:\n",
    "    assert (date_sorter() == s_test).all()\n",
    "    print(\"Passed repeatability check\")\n",
    "except:\n",
    "    print(\"Failed repeatability check\")\n",
    "\n",
    "# check if the result has the expected index\n",
    "try:\n",
    "    assert type(date_sorter().index) == pd.RangeIndex\n",
    "    assert (date_sorter().index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "    print(\"Passed index check\")\n",
    "except:\n",
    "    print(\"Failed index check\")\n",
    "\n",
    "# check the tie-break sort for a sample of records where some have the same date\n",
    "# note that this only tests a sample and does not check the entire answer\n",
    "try:\n",
    "    i_test = [s_test.index[s_test == v].values[0]\n",
    "              for v in [318, 369, 493, 252, 314, 410, 490]]\n",
    "    assert sorted(i_test) == i_test\n",
    "    print(\"Passed secondary sort sample check\")\n",
    "except:\n",
    "    print(\"Failed secondary sort sample check\")\n",
    "\n",
    "def run_v_check(s_test):\n",
    "    \"\"\"\n",
    "    Check if the parsed dates appear to be correct and correctly sorted.\n",
    "    The check works by producing some test checksums\n",
    "    if you get for example a False entry in the agree column for\n",
    "    index value 20 that would mean you have at least one incorrectly\n",
    "    parsed or incorrectly sorted date in the **output** index\n",
    "    range 20,21,...,29\n",
    "    The results of the test are printed.\n",
    "    Args:\n",
    "    s_test: Series such as produced by date_sorter()\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        v_check = pd.DataFrame({'correct':\n",
    "        [6695, 14428, 16742, 9275, 12290, 14654, 9421, 10185, 11464, 16491,\n",
    "         11797, 14036, 15459, 9412, 13069, 10400, 10498, 14322, 13274, 11001,\n",
    "         11383, 11910, 10977, 9692, 10199, 10187, 15456, 13491, 9186, 13646,\n",
    "         11142, 13724, 10994, 12905, 15968, 16648, 13966, 14607, 16932, 14622,\n",
    "         17942, 18220, 17818, 18305, 19633, 12522, 13978, 18445, 20156, 14797],\n",
    "        'learner':[\n",
    "        (s_test.iloc[10*i:(i+1)*10].values * np.array(range(1,11))).sum() for i in range(50)]},\n",
    "        index=range(0,500,10)).assign(agree=lambda x:x['correct']==x['learner'])\n",
    "        print(\"Values checksums:\")\n",
    "        print(v_check)\n",
    "        assert v_check['agree'].all()\n",
    "        print(\"Passed values check\")\n",
    "    except:\n",
    "        print(\"Failed values check\")\n",
    "    return\n",
    "\n",
    "run_v_check(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0843c1f0ad2aaa45fa9ac4012f1aa43",
     "grade": true,
     "grade_id": "cell-373f878879c00996",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e2f5bb6bab79c07a81ec366c46c4d49",
     "grade": true,
     "grade_id": "cell-0ebae76e6cd794be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
